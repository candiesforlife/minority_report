{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T22:39:58.111015Z",
     "start_time": "2021-01-03T22:39:58.105539Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T22:39:59.074871Z",
     "start_time": "2021-01-03T22:39:58.984525Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../raw_data/test_df.pickle', 'rb') as f:\n",
    "            test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T22:39:59.432169Z",
     "start_time": "2021-01-03T22:39:59.426045Z"
    }
   },
   "outputs": [],
   "source": [
    "def from_meters_to_steps(lat_meters, lon_meters):\n",
    "  '''\n",
    "  Returns the latitude and longitude step to use for the grid buckets\n",
    "  lat_meters, lon_meters are defined in trainer.py\n",
    "  They are equivalent to the bucket size desired\n",
    "  '''\n",
    "\n",
    "  # Position in decimal degrees\n",
    "  lat = 40\n",
    "  lon = -73\n",
    "\n",
    "  # Earthâ€™s radius (sphere)\n",
    "  R = 6378137\n",
    "\n",
    "  # Offset in meters\n",
    "  dn = lat_meters\n",
    "  de = lon_meters\n",
    "\n",
    "  # Coordinate offsets in radians\n",
    "  dLat = dn / R\n",
    "  dLon = de / (R * np.cos(np.pi * lat / 180))\n",
    "\n",
    "  # Offset position, decimal degrees\n",
    "  latO = dLat * 180 / np.pi\n",
    "  lonO = dLon * 180 / np.pi\n",
    "\n",
    "  return latO, lonO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T22:39:59.925354Z",
     "start_time": "2021-01-03T22:39:59.914462Z"
    }
   },
   "outputs": [],
   "source": [
    "def from_coord_to_matrix(df, lat_meters, lon_meters): #lat_meters, lon_meters\n",
    "    \"\"\"\n",
    "    Returns 3D matrix\n",
    "    Each coordinate is assigned to a bucket of size lat_meters and lon_meters\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Adds 'time_index' column to dataframe\n",
    "    ind = {time: index for index, time in enumerate(np.sort(df['six_hour_date'].unique()))}\n",
    "    df['time_index'] = df['six_hour_date'].map(ind)\n",
    "\n",
    "    # Matrix starting point\n",
    "    grid_offset = np.array([-df['latitude'].max(), df['longitude'].min(), 0]) \n",
    "    \n",
    "    # Converts bucket size (meters) to lat & lon spacing\n",
    "    lat_spacing, lon_spacing = from_meters_to_steps(lat_meters, lon_meters)\n",
    "    \n",
    "    # Euclidian spacing\n",
    "    grid_spacing = np.array([lat_spacing , lon_spacing, 1])\n",
    "    \n",
    "    # Gets point coordinates\n",
    "    coords = np.array([(-lat, lon, t_ind) for lat, lon, t_ind \\\n",
    "                   in zip(df['latitude'], df['longitude'], df['time_index'])])\n",
    "\n",
    "    # Converts point to index\n",
    "    indexes = np.round((coords - grid_offset)/grid_spacing).astype('int')\n",
    "    \n",
    "    X = indexes[:, 0]\n",
    "    Y = indexes[:, 1]\n",
    "    Z = indexes[:, 2]\n",
    "\n",
    "    # 75th precinct maximum & minimum points\n",
    "    lat_min, lat_max, lon_max, lon_min = (40.6218192717505,\n",
    "                                          40.6951504231971,\n",
    "                                          -73.90404639808888,\n",
    "                                          -73.83559344190869)\n",
    "\n",
    "    lat_diff = lat_max - lat_min # Distance in lat that makes up width of precinct 75\n",
    "    lon_diff = lon_min - lon_max # Distance in lon that makes up width of precinct 75\n",
    "\n",
    "    # Dim 1: distance of precinct in lat / lat_spacing\n",
    "    a = np.zeros((np.round(lat_diff / lat_spacing).astype('int') + 1,\n",
    "                 np.round(lon_diff / lon_spacing).astype('int') + 1,\n",
    "                 Z.max() + 1))\n",
    "\n",
    "    a[X, Y, Z] = 1\n",
    "\n",
    "    lat_size = a.shape[1]\n",
    "    lon_size = a.shape[2]\n",
    "    img3D_non_conv = a\n",
    "\n",
    "    return img3D_non_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T22:40:01.199638Z",
     "start_time": "2021-01-03T22:40:01.036310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_coord_to_matrix(test_df, 15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def gaussian_filtering_train(self):\n",
    "    '''\n",
    "      Returns img3D convoluted\n",
    "    '''\n",
    "\n",
    "    self.img3D_conv_train = gaussian_filter(self.img3D_non_conv_train,\n",
    "        sigma = (self.sigma_x, self.sigma_y, self.sigma_z))\n",
    "\n",
    "    return self.img3D_conv_train\n",
    "\n",
    "########\n",
    "# Input: Stacking et all.\n",
    "\n",
    "def stacking_train(self, window, lat_step, lon_step, time_step):\n",
    "    '''\n",
    "        Returns stacked crimes.\n",
    "    '''\n",
    "    grid_offset = np.array([0,0,0]) # Where do you start\n",
    "    #new steps from precise grid\n",
    "    grid_spacing = np.array([lat_step , lon_step, time_step])\n",
    "    #get points coordinates\n",
    "    coords = np.argwhere(window)\n",
    "    flat = window.flatten()\n",
    "    values = flat[flat !=0]\n",
    "    # Convert point to index\n",
    "    indexes = np.round((coords - grid_offset)/grid_spacing).astype('int')\n",
    "    X = indexes[:,0]\n",
    "    Y = indexes[:,1]\n",
    "    Z = indexes[:,2]\n",
    "    #virgin matrix: 256 is arbitrary size that works in model\n",
    "    stacked_crimes = np.zeros((192, 132, Z.max() + 2))\n",
    "\n",
    "    for i in range(len(indexes)):\n",
    "\n",
    "        if stacked_crimes[X[i], Y[i], Z[i]] == 0:\n",
    "            stacked_crimes[X[i], Y[i], Z[i]] = values[i]\n",
    "        else:\n",
    "            stacked_crimes[X[i], Y[i], Z[i]] += values[i]\n",
    "\n",
    "    return stacked_crimes\n",
    "\n",
    "def get_observation_target_train(self,\n",
    "                       obs_timeframe,obs_lat,obs_lon, obs_time,\n",
    "                       target_timeframe,  tar_lat,tar_lon, tar_time):\n",
    "    '''\n",
    "    output an observation of x_length consecutive images and the y_length next images as the target\n",
    "    obs_step, obs_timeframe, target_step, target_timeframe : unit = hours\n",
    "    '''\n",
    "\n",
    "    # sample length to absorb impact of gaussian time sigma\n",
    "    sample_length = obs_timeframe + (self.raw_z + 1) + target_timeframe\n",
    "\n",
    "    # finds starting position\n",
    "    position = np.random.randint(0, self.img3D_conv_train.shape[2] - sample_length)\n",
    "\n",
    "    # samples in train and test dfs\n",
    "    subsample = self.img3D_conv_train[:, :, position : position + sample_length]\n",
    "\n",
    "    # divide the subsample in X and y\n",
    "    observations = subsample[:, :, : obs_timeframe]\n",
    "\n",
    "    targets = subsample[:, :, - target_timeframe : ]\n",
    "\n",
    "    # stacked images\n",
    "    observation = self.stacking_train(observations, obs_lat, obs_lon, obs_time)\n",
    "\n",
    "    target = self.stacking_train(targets, tar_lat, tar_lon, tar_time)\n",
    "\n",
    "    return observation, target\n",
    "\n",
    "def get_X_y_train(self, nb_observations_train, obs_tf,obs_lat,obs_lon, obs_time,\n",
    "                tar_tf, tar_lat,tar_lon, tar_time):\n",
    "    '''\n",
    "    outputs n observations and their associated targets\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for n in range(nb_observations_train):\n",
    "        print(f'Creating observation {n} out of {nb_observations_train}')\n",
    "        X_subsample, y_subsample = self.get_observation_target_train(obs_tf,\n",
    "                                    obs_lat,obs_lon, obs_time,\n",
    "                                    tar_tf,  tar_lat,tar_lon, tar_time)\n",
    "        X.append(X_subsample)\n",
    "        y.append(y_subsample)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    self.X_train = X\n",
    "    self.y_train = y\n",
    "\n",
    "    return self.X_train, self.y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
